{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='graphics/013019_JR_panda-diet_feat.jpg'>\n",
    "\n",
    "# Introduction to Pandas, Part 1\n",
    "\n",
    "To date, we have worked with a number of ways to store data:\n",
    "1. Lists\n",
    "1. Tubles\n",
    "1. Dictionaries\n",
    "\n",
    "With these structures, we have stored:\n",
    "1. Integers\n",
    "1. Floats\n",
    "1. Strings\n",
    "\n",
    "And while we will continue to use these structures in our programming, there is one structure that we will use more than any other. In Excel, the structure is called a *spreadsheet*. In SQL, the structure is called a *table*. And in Python, the structure is called a *DataFrame*.\n",
    "\n",
    "To form, access, and manipulate a *DataFrame* in Python, we will use one of the most flexible, efficient, and powerful libraries for scientific computing, ***Pandas***.\n",
    "\n",
    "## DataFrames and Tables\n",
    "\n",
    "Whether you are using SQL or Excel, you are familiar with the basic structure of a *DataFrame* or a table. *DataFrames* allow us to keep all forms of data in an orderly, searchable, and manipulatable form. Consisting of rows - called *observations* in Python - and columns - called *features* in Python, DataFrames order our data in such a way that we can easily keep track of the data we have, and we can recall the data we have efficiently and effectively. To work with DataFrames in Python, *Pandas* is the library of services that we use. \n",
    "\n",
    "<img src='graphics/Screen Shot 2019-10-09 at 4.52.12 AM.png'>\n",
    "          \n",
    "Take a look at the DataFrame above, and you will see something familiar. This particular DataFrame contains information about school schooting incidents. You will see strings and integers in this table, all of which can be stored in a DataFrame. In fact, Pandas' DataFrames in Python can store\n",
    "1. Integers\n",
    "1. Floats\n",
    "1. Strings\n",
    "1. Lists\n",
    "1. Tuples\n",
    "1. Dictionaries\n",
    "1. URLs\n",
    "\n",
    "With Pandas, you can store and recover your data in a number of ways to include Excel spreadsheets. But most commonly, you will store DataFrames as .csv files (comma separated format), which can be read by Python, Excel, or SQL readers. \n",
    "\n",
    "\n",
    "# Importing Pandas\n",
    "\n",
    "The Pandas library is not inherently resident within Python. As such, we need to tell Python to load the library. In Python, loading a library is called *importing a library* and it is done with the `import` command. \n",
    "\n",
    "Importing Pandas into Python is simple. You use the following line of code to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imported libraries before such as `random`, so the `import` command may be familiar to you. What is different this time is our use of the `as` command. Later, as we use the Pandas library in our code, we will have to refer Python to the library - so Python knows to what library to associate the follow-on commands. We can do this in two ways. We can repeatedly type `pandas.` OR we can shorten this work by referring to the Pandas in another way. By telling Python to associate the variable `pd` (import AS pd), \n",
    "1. Python will remember that whenever we use the variable `pd`, it will associate it with Pandas, and \n",
    "1. it saves us keystrokes in typing.\n",
    "\n",
    "We will see this in action in our next example. \n",
    "\n",
    "# Creating a DataFrame\n",
    "\n",
    "To create a Pandas DataFrame, we use the following command. \n",
    "\n",
    "(Notice that we are associating the entire DataFrame with the variable `df`. This is a fairly common abbreviation within Python. In most cases, when you come across a variable that contains the letters `df`, you can safely assume that it is referring to a DataFrame.)\n",
    "\n",
    "## Creating an Empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame from a Python List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list1 = [1,2,3,4,5]\n",
    "df = pd.DataFrame(num_list1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing a CSV File as a Pandas DataFrame\n",
    "\n",
    "In our work with dictionaries, we met four friends (Bob, Carol, Ted, Alice), and we stored their information in dictionaries. Now let's look at how a the same information would be stored in a DataFrame.\n",
    "\n",
    "Run the next block of code to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/friends.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAVEAT:\n",
    ">Pandas loads a DataFrame into your computer's memory (whichever computer you are using). As such, your computer's memmory is going to be a limiting factor on how large of a DataFrame you can load. \n",
    "\n",
    ">Additionally, if you are running on a computer with smaller than an i7 processor, you **will** notice a slow down in your processing as your DataFrames get larger (and I mean those above 10,000 observations and 20 features). So if you have been needing a valid reason to upgrade your computer, *this is the best reason of which I can find.*\n",
    "\n",
    "\n",
    "# Basics of Examining a DataFrame\n",
    "\n",
    "As any data person knows, knowing your data is vital to working with it. And as every data person also knows, the first steps in this is to look at the data.\n",
    "\n",
    "So far the data we have been working with has been incredibly (almost unrealistically) small. If you work with data regularly, you know that this will not always be the case. Therefore, you will want to look over the data - at a basic level for now - in order to get a feel for it. \n",
    "\n",
    "Here are some Pandas commands to help you learn your data - at the most basic levels for now.\n",
    "\n",
    "To learn these, we will use a new dataset. Run the next block of code to load our mystery dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/X17c.csv')\n",
    "del df['Unnamed: 0']# This line is used to delete a useless column that this dataset picks up in transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .head( )\n",
    "\n",
    "To look at the first five observations of a DataFrame, we use the `.head()` command. By default, this command will show you the first five (5) observations of data in a dataset. However, if you place a numeral between the parentheses, it will show you that many observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also display *n* observations of the data by passing the value of *n* to the `.head()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) #This will show the first ten (10) rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .tail( )\n",
    "\n",
    "Alternately, you can look at the last observations of the DataFrame by using the `.tail()` method. Like the `.head()` method, `.tail()` will show the last five (5) observations of data by default, or you can pass an *n* value to the `.tail()` method to show however many observations you wish to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .sample( )\n",
    "\n",
    "You can also use the `.sample()` method to see a random sample of the data. Like `.head()`, you can pass an *n* value to see however many random observations you wish to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .shape\n",
    "\n",
    "To see the \"shape\" of your DataFrame, use the `.shape` method. This will return the number of observations and number of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .keys( ) & .columns\n",
    "\n",
    "When we want to look at the feature names (column names) of your DataFrame, you can use either the `.keys()` or the `.columns` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .info( )\n",
    "\n",
    "Typical problems when working with new datasets are:\n",
    "1. Missing Values (very common and quite frustrating)\n",
    "1. Unexpected types (string/object instead of int/float)\n",
    "1. Dirty data (commas, dollar signs, special charaters, etc. (90% of a data scientist's/analysis' time is spent cleaning data!)\n",
    "1. Blank values that are actually \"non-null\" or single white-space characters\n",
    "\n",
    "**Types** are very important. They impact the way data will be represented in our machine learning models, how data can be joined, whether or not math operators can be applied, and when you can encounter unexpected results.\n",
    "\n",
    "\n",
    "The `.info()` is a function that is available on every **DataFrame** object. It gives you information about:\n",
    "1. Name of the feature/column/variable attribute\n",
    "1. Type of index (`RangeIndex` is default)\n",
    "1. Count of non-null values by feature/column/attribute\n",
    "1. Type of data contained in feature/column/attribute\n",
    "1. Unique counts of `dtypes` (Pandas data types)\n",
    "1. Memory usage of our dataset\n",
    "\n",
    "Run the next block of code to see what `.info()` returns as results for our dataset. \n",
    "\n",
    "(**Note:** This dataset is pretty clean, first, because I cleaned it already and, second, because this is training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .describe( )\n",
    "\n",
    "The `.describe()` function is very useful for quanitative data examination - a quick look at your data. It gives you some of the basic descriptive statistics for numeric features. \n",
    "\n",
    "To demonstrate this, we will use the `df['moon_phaseid']` column. These numbers represent the phases of the moon on the night of the reported incident, 0(New Moon) - 4(Full Moon). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['moon_phaseid'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .values_count( )\n",
    "\n",
    "The `.value_counts()` function allows us to look closer at any column/feature in the dataset. To demonstrate this, we will use the `df['day_of_week']` feature to see how many incidents occur on each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Accessing a Feature (Column) in a DataFrame\n",
    "\n",
    "You can access a feature (column) of a DataFrame in one of two methods.\n",
    "\n",
    "*Method 1* - The .Dot method (note that this will not work if there are spaces in the feature name.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.day_of_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Method 2* - The Square Brackets method (note that this will work in all instances.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Rows and Navigating a DataFrame using .loc[ ]\n",
    "\n",
    "There are two methods to navigate a DataFrame by position, the `.loc[]` and the `.iloc[]` methods. For now, we will only focus on the `.loc[]` method as it is easier and most often used. \n",
    "\n",
    "The `.loc[]` method allows you to use the name of the column/feature and the index number of the row. For example, if you want to look at the observation/row in index 300, you would simply write the code in the next block. Run the block and see what you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By simply calling the row index number (the first place in a `.loc[]` command), it will give you all of the information on that observation. \n",
    "\n",
    "To call a specific 'cell' (if that makes it easier imagine), then the syntax in the [ ] is row, then column. As in our next example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[300, 'crime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `.loc[]` defaults to observations/rows as the dominant entry type and not features/columns, the syntax is a bit different for calling an entire feature/column. Here, we need to tell Python that we want all of the observations for the entire feature. In `.loc[]`, the colon : is the ALL command. So, as we see in the next example, we are telling python to go to the DataFrame (df), location (.loc), all rows : in feature 'feature title'.\n",
    "\n",
    "(***Note***: Because of the size of our DataFrame, we are also using the `.head()` command to look only at the first five rows/observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'day_of_week'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Note about Style\n",
    "\n",
    "You may have noticed that the feature names in our DataFrame are\n",
    "1. all lower case\n",
    "1. do not have spaces\n",
    "\n",
    "While you can certainly use upper and lower case for your feature names, AND you can use spaces in your feature name, it will at times cause problems with coding. For example, if you recall our discussion above on the .DOT method of accessing a feature (`df.day_of_week`), spaces in your feature name prevents you from using this shorthand and limits you to using the square bracket method. In a recent poll by kevin Markham on LinkedIn, most pythonistas prefer the square bracket method rather than the .DOT method. \n",
    "\n",
    "Whatever your preferred style, it is more important that you use the same convention throughout your code.\n",
    "\n",
    "# Practice\n",
    "\n",
    "---\n",
    "\n",
    "Now that we know a little bit about basic DataFrame use, let's practice on a new dataset.\n",
    "\n",
    "> Pro tip:  You can use the \"tab\" key to browse filesystem resources when your cursor is in a string to get a relative reference to the files that can be loaded in Jupyter notebook.  Remember, you have to use your arrow keys to navigate the files populated in the UI. \n",
    "\n",
    "<img src=\"https://snag.gy/IlLNm9.jpg\">\n",
    "\n",
    "1. Find and load the \"diamonds\" dataset into a DataFrame (in the datasets directory).\n",
    "1. Print out the columns.\n",
    "1. What does the dataset look like in terms of dimensions?\n",
    "1. Check the types of each column.\n",
    "  1. What is the most common type?\n",
    "  1. How many entries are there?\n",
    "  1. How much memory does this dataset consume?\n",
    "1. Examine the summary statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds_df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
